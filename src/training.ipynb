{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torchvision.io import read_image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision \n",
    "from torchvision import transforms\n",
    "import timm\n",
    "import segmentation_models_pytorch as smp\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataset import *\n",
    "\n",
    "sys.path.append('/'.join(os.getcwd().split('\\\\')[:2]) + '/utils')\n",
    "from log import *\n",
    "\n",
    "from model import unet_model \n",
    "from mask_to_rgb import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_path = []\n",
    "for root, dirs, files in os.walk(TRAIN_IMAGES_DIR):\n",
    "    for file in files:\n",
    "        path = os.path.join(root,file)\n",
    "        train_images_path.append(path)\n",
    "        \n",
    "len(train_images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_masks_path = []\n",
    "for root, dirs, files in os.walk(TRAIN_MASKS_DIR):\n",
    "    for file in files:\n",
    "        path = os.path.join(root,file)\n",
    "        train_masks_path.append(path)\n",
    "        \n",
    "len(train_masks_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NeoPolypDataset(\n",
    "    img_dir=TRAIN_IMAGES_DIR, \n",
    "    label_dir=TRAIN_MASKS_DIR, \n",
    "    resize=(256, 256), \n",
    "    transform=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_data = []\n",
    "labels_data = []\n",
    "for x,y in dataset:\n",
    "    images_data.append(x)\n",
    "    labels_data.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet_model\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(TRAIN_RATIO * len(images_data))\n",
    "val_size = len(images_data) - train_size\n",
    "train_dataset = CustomDataset(images_data[:train_size], labels_data[:train_size], transform=train_transformation)\n",
    "val_dataset = CustomDataset(images_data[train_size:], labels_data[train_size:], transform=val_transformation)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCHSIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCHSIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfisherman611\u001b[0m (\u001b[33mfisherman611-hanoi-university-of-science-and-technology\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Administrator\\_netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\UNet-for-Colonoscopy-Polyp-Segmentation\\src\\wandb\\run-20241123_195835-03i3njre</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fisherman611-hanoi-university-of-science-and-technology/UNet%20for%20Colonoscopy%20Polyp%20Segmentation/runs/03i3njre' target=\"_blank\">fluent-wind-1</a></strong> to <a href='https://wandb.ai/fisherman611-hanoi-university-of-science-and-technology/UNet%20for%20Colonoscopy%20Polyp%20Segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fisherman611-hanoi-university-of-science-and-technology/UNet%20for%20Colonoscopy%20Polyp%20Segmentation' target=\"_blank\">https://wandb.ai/fisherman611-hanoi-university-of-science-and-technology/UNet%20for%20Colonoscopy%20Polyp%20Segmentation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fisherman611-hanoi-university-of-science-and-technology/UNet%20for%20Colonoscopy%20Polyp%20Segmentation/runs/03i3njre' target=\"_blank\">https://wandb.ai/fisherman611-hanoi-university-of-science-and-technology/UNet%20for%20Colonoscopy%20Polyp%20Segmentation/runs/03i3njre</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/fisherman611-hanoi-university-of-science-and-technology/UNet%20for%20Colonoscopy%20Polyp%20Segmentation/runs/03i3njre?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x15bde529590>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(\n",
    "    key = \"25283834ecbe7bd282505b0721ea3adcd8e789d3\",\n",
    ")\n",
    "wandb.init(\n",
    "    project = \"UNet for Colonoscopy Polyp Segmentation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/50 [00:16<?, ?it/s, Train Loss=0.664, Val Loss=0.352]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Validation Loss: 0.3519981274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|▏         | 1/50 [00:33<14:03, 17.22s/it, Train Loss=0.263, Val Loss=0.193]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Validation Loss: 0.1927215595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   4%|▍         | 2/50 [00:49<13:22, 16.72s/it, Train Loss=0.157, Val Loss=0.127]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Validation Loss: 0.1273323401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   6%|▌         | 3/50 [01:06<13:01, 16.62s/it, Train Loss=0.112, Val Loss=0.125]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Validation Loss: 0.1253423387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   8%|▊         | 4/50 [01:22<12:45, 16.65s/it, Train Loss=0.0879, Val Loss=0.0813]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Validation Loss: 0.0813373920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  10%|█         | 5/50 [01:38<12:23, 16.53s/it, Train Loss=0.0756, Val Loss=0.0693]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Validation Loss: 0.0693384896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  12%|█▏        | 6/50 [01:55<12:03, 16.44s/it, Train Loss=0.0638, Val Loss=0.0656]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Validation Loss: 0.0655814022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  14%|█▍        | 7/50 [02:11<11:45, 16.42s/it, Train Loss=0.0539, Val Loss=0.0645]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Validation Loss: 0.0645412860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  16%|█▌        | 8/50 [02:28<11:29, 16.43s/it, Train Loss=0.0466, Val Loss=0.0593]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Validation Loss: 0.0592633758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  18%|█▊        | 9/50 [02:44<11:16, 16.50s/it, Train Loss=0.0457, Val Loss=0.056] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Validation Loss: 0.0560347214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  20%|██        | 10/50 [03:01<10:58, 16.46s/it, Train Loss=0.0434, Val Loss=0.047]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Validation Loss: 0.0470285302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  22%|██▏       | 11/50 [03:17<10:41, 16.45s/it, Train Loss=0.042, Val Loss=0.0425]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Validation Loss: 0.0424625209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  26%|██▌       | 13/50 [03:34<10:03, 16.31s/it, Train Loss=0.0372, Val Loss=0.0498]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Validation Loss: 0.0498114112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  26%|██▌       | 13/50 [03:50<10:03, 16.31s/it, Train Loss=0.0321, Val Loss=0.0411]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Validation Loss: 0.0411131260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  30%|███       | 15/50 [04:07<09:41, 16.60s/it, Train Loss=0.0336, Val Loss=0.0499]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Validation Loss: 0.0499123521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  32%|███▏      | 16/50 [04:25<09:34, 16.88s/it, Train Loss=0.0346, Val Loss=0.0451]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Validation Loss: 0.0451007616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  34%|███▍      | 17/50 [04:43<09:26, 17.16s/it, Train Loss=0.0284, Val Loss=0.055] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Validation Loss: 0.0550011825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  36%|███▌      | 18/50 [05:00<09:12, 17.27s/it, Train Loss=0.0297, Val Loss=0.0441]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Validation Loss: 0.0440527388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  36%|███▌      | 18/50 [05:18<09:12, 17.27s/it, Train Loss=0.0258, Val Loss=0.0406]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50], Validation Loss: 0.0405942611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  38%|███▊      | 19/50 [05:36<09:05, 17.60s/it, Train Loss=0.0225, Val Loss=0.0366]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Validation Loss: 0.0366235203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  40%|████      | 20/50 [05:54<08:53, 17.77s/it, Train Loss=0.0203, Val Loss=0.0319]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50], Validation Loss: 0.0318900984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  42%|████▏     | 21/50 [06:11<08:34, 17.74s/it, Train Loss=0.0198, Val Loss=0.0302]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50], Validation Loss: 0.0301571720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  46%|████▌     | 23/50 [06:27<07:39, 17.01s/it, Train Loss=0.0214, Val Loss=0.0458]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50], Validation Loss: 0.0457686432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  48%|████▊     | 24/50 [06:43<07:14, 16.69s/it, Train Loss=0.0226, Val Loss=0.0395]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50], Validation Loss: 0.0395099105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  50%|█████     | 25/50 [06:59<06:51, 16.48s/it, Train Loss=0.0198, Val Loss=0.0343]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50], Validation Loss: 0.0342995658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  52%|█████▏    | 26/50 [07:15<06:31, 16.33s/it, Train Loss=0.0188, Val Loss=0.0442]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50], Validation Loss: 0.0442179225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  54%|█████▍    | 27/50 [07:31<06:13, 16.23s/it, Train Loss=0.0185, Val Loss=0.0392]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50], Validation Loss: 0.0391507954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  56%|█████▌    | 28/50 [07:47<05:55, 16.15s/it, Train Loss=0.0169, Val Loss=0.0351]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50], Validation Loss: 0.0351057690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  58%|█████▊    | 29/50 [08:03<05:38, 16.12s/it, Train Loss=0.0148, Val Loss=0.0404]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50], Validation Loss: 0.0404432864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  60%|██████    | 30/50 [08:19<05:22, 16.12s/it, Train Loss=0.0145, Val Loss=0.0352]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50], Validation Loss: 0.0352314043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  62%|██████▏   | 31/50 [08:35<05:06, 16.11s/it, Train Loss=0.0151, Val Loss=0.0404]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50], Validation Loss: 0.0403906684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  64%|██████▍   | 32/50 [08:51<04:49, 16.09s/it, Train Loss=0.0137, Val Loss=0.039] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50], Validation Loss: 0.0390148133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  66%|██████▌   | 33/50 [09:07<04:33, 16.07s/it, Train Loss=0.0143, Val Loss=0.0403]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50], Validation Loss: 0.0402796206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  68%|██████▊   | 34/50 [09:23<04:16, 16.05s/it, Train Loss=0.0255, Val Loss=0.0389]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50], Validation Loss: 0.0389368768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  70%|███████   | 35/50 [09:39<04:00, 16.03s/it, Train Loss=0.019, Val Loss=0.0379] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50], Validation Loss: 0.0379241939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  72%|███████▏  | 36/50 [09:55<03:44, 16.02s/it, Train Loss=0.0211, Val Loss=0.0491]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50], Validation Loss: 0.0491135181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  74%|███████▍  | 37/50 [10:11<03:28, 16.03s/it, Train Loss=0.0215, Val Loss=0.0394]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50], Validation Loss: 0.0394111402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  76%|███████▌  | 38/50 [10:27<03:12, 16.02s/it, Train Loss=0.0135, Val Loss=0.0476]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50], Validation Loss: 0.0475903951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  78%|███████▊  | 39/50 [10:43<02:56, 16.00s/it, Train Loss=0.0136, Val Loss=0.044] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50], Validation Loss: 0.0440221957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  80%|████████  | 40/50 [10:59<02:39, 15.99s/it, Train Loss=0.0122, Val Loss=0.0411]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50], Validation Loss: 0.0410780024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  82%|████████▏ | 41/50 [11:15<02:23, 15.99s/it, Train Loss=0.0114, Val Loss=0.0396]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50], Validation Loss: 0.0396317099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  84%|████████▍ | 42/50 [11:31<02:07, 15.98s/it, Train Loss=0.0135, Val Loss=0.0402]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50], Validation Loss: 0.0402024651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  86%|████████▌ | 43/50 [11:47<01:51, 15.97s/it, Train Loss=0.0122, Val Loss=0.0375]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50], Validation Loss: 0.0374560626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  88%|████████▊ | 44/50 [12:03<01:35, 15.99s/it, Train Loss=0.0107, Val Loss=0.0407]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50], Validation Loss: 0.0406943554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  90%|█████████ | 45/50 [12:19<01:19, 15.99s/it, Train Loss=0.0146, Val Loss=0.0478]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50], Validation Loss: 0.0477803457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  92%|█████████▏| 46/50 [12:35<01:04, 16.01s/it, Train Loss=0.0113, Val Loss=0.037] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50], Validation Loss: 0.0369942011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  94%|█████████▍| 47/50 [12:51<00:48, 16.02s/it, Train Loss=0.0117, Val Loss=0.0469]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50], Validation Loss: 0.0468833219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  96%|█████████▌| 48/50 [13:07<00:32, 16.04s/it, Train Loss=0.0114, Val Loss=0.0429]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50], Validation Loss: 0.0429415341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  98%|█████████▊| 49/50 [13:23<00:16, 16.03s/it, Train Loss=0.00959, Val Loss=0.0403]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50], Validation Loss: 0.0402817191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 50/50 [13:40<00:00, 16.40s/it, Train Loss=0.00991, Val Loss=0.0374]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Validation Loss: 0.0374240418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Move the model to the appropriate device\n",
    "model.to(device)\n",
    "\n",
    "# Define the loss function and initialize the best validation loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# Create a progress bar for tracking epochs\n",
    "epoch_bar = tqdm(total=EPOCHS, desc='Training Progress')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Training loop\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device).squeeze(1).long()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate training loss\n",
    "        total_train_loss += loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "\n",
    "    # Validation loop\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device).squeeze(1).long()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Compute validation loss\n",
    "            total_val_loss += criterion(outputs.float(), labels.long()).item()\n",
    "\n",
    "    # Calculate average losses\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "    # Log progress and update the progress bar\n",
    "    print(f\"Epoch [{epoch + 1}/{EPOCHS}], Validation Loss: {avg_val_loss:.10f}\")\n",
    "    epoch_bar.set_postfix({'Train Loss': avg_train_loss, 'Val Loss': avg_val_loss})\n",
    "\n",
    "    # Save the model if validation loss improves\n",
    "    if total_val_loss < best_val_loss:\n",
    "        best_val_loss = total_val_loss\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'loss': total_val_loss,\n",
    "        }\n",
    "        torch.save(checkpoint, f'{new_cwd}/checkpoint/model.pth')\n",
    "    \n",
    "    # Log metrics to wandb\n",
    "    wandb.log({'Train Loss': avg_train_loss, 'Val Loss': avg_val_loss})\n",
    "\n",
    "    # Update the epoch progress bar\n",
    "    epoch_bar.update(1)\n",
    "\n",
    "# Close the progress bar\n",
    "epoch_bar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_7760\\3760274449.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(f'{new_cwd}/checkpoint/model.pth')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (encoder): ResNetEncoder(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): UnetDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleList(\n",
       "      (0): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(f'{new_cwd}/checkpoint/model.pth')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for i in os.listdir(TEST_DIR):\n",
    "    img_path = os.path.join(TEST_DIR, i)\n",
    "    ori_img = cv2.imread(img_path)\n",
    "    ori_img = cv2.cvtColor(ori_img, cv2.COLOR_BGR2RGB)\n",
    "    ori_w = ori_img.shape[0]\n",
    "    ori_h = ori_img.shape[1]\n",
    "    img = cv2.resize(ori_img, (256, 256))\n",
    "    transformed = val_transformation(image=img)\n",
    "    input_img = transformed[\"image\"]\n",
    "    input_img = input_img.unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        output_mask = model.forward(input_img).squeeze(0).cpu().numpy().transpose(1,2,0)\n",
    "    mask = cv2.resize(output_mask, (ori_h, ori_w))\n",
    "    mask = np.argmax(mask, axis=2)\n",
    "    mask_rgb = mask_to_rgb(mask, COLOR_DICT)\n",
    "    mask_rgb = cv2.cvtColor(mask_rgb, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(\"{}/prediction/{}\".format(new_cwd, i), mask_rgb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\019410b1fcf0625f608b4ce97629ab55.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\02fa602bb3c7abacdbd7e6afd56ea7bc.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\0398846f67b5df7cdf3f33c3ca4d5060.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\05734fbeedd0f9da760db74a29abdb04.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\05b78a91391adc0bb223c4eaf3372eae.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\0619ebebe9e9c9d00a4262b4fe4a5a95.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\0626ab4ec3d46e602b296cc5cfd263f1.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\0a0317371a966bf4b3466463a3c64db1.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\0a5f3601ad4f13ccf1f4b331a412fc44.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\0af3feff05dec1eb3a70b145a7d8d3b6.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\0fca6a4248a41e8db8b4ed633b456aaa.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\1002ec4a1fe748f3085f1ce88cbdf366.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\1209db6dcdda5cc8a788edaeb6aa460a.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\13dd311a65d2b46d0a6085835c525af6.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\1531871f2fd85a04faeeb2b535797395.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\15fc656702fa602bb3c7abacdbd7e6af.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\1ad4f13ccf1f4b331a412fc44655fb51.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\1b62f15ec83b97bb11e8e0c4416c1931.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\1c0e9082ea2c193ac8d551c149b60f29.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\1db239dda50f954ba59c7de13a35276a.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\26679bff55177a34fc01019eec999fd8.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\268d4b4ef4d95ceea11957998906d369.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\27738677a6b1f2c6d40b3bbba8f6c704.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\285e26c90e1797c77826f9a7021bab9f.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\2a365b5574868eb60861ee1ff0b8a4f6.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\2cd066b9fdbc3bbc04a3afe1f119f21b.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\2d9e593b6be1ac29adbe86f03d900fd1.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\2ed9fbb63b28163a745959c03983064a.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\30c2f4fc276ed9f178dc2f4af6266509.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\314fe384eb2ba3adfda6c1899fdc9837.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\318ecf467d7ad048df39beb176363408.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\3425b976973f13dd311a65d2b46d0a60.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\343f27ebc5d92b9076135d76d0bbd4ce.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\3657e4314fe384eb2ba3adfda6c1899f.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\391adc0bb223c4eaf3372eae567c94ea.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\395e56a6d9ba9d45c3dbc695325ded46.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\39d6aad6bb0170a40ed32deef71fbe08.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\39dda50f954ba59c7de13a35276a4764.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\3b8318ecf467d7ad048df39beb176363.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\3bbc04a3afe1f119f21b248d152b672a.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\3c3ca4d5060a633a8d5b2b2b55157b77.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\3c692195f853af7f8a4df1ec859759b7.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\3c84417fda8019410b1fcf0625f608b4.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\3dd311a65d2b46d0a6085835c525af63.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\3f33c3ca4d5060a633a8d5b2b2b55157.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\41ed86e58224cb76a67d4dcf9596154e.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\425b976973f13dd311a65d2b46d0a608.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\4417fda8019410b1fcf0625f608b4ce9.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\45b21960c94b0aab4c024a573c692195.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\461c2a337948a41964c1d4f50a5f3601.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\4baddc22268d4b4ef4d95ceea1195799.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\4c1711b62f15ec83b97bb11e8e0c4416.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\4ca6160127cd1d5ff99c267599fc487b.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\4e2a6e51d077bad31c8c5f54ffaa27a6.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\4e8bfb905b78a91391adc0bb223c4eaf.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\4ef4d95ceea11957998906d3694abb47.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\4f437f0019f7e6af7d7147763bdfb928.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\4fda8daadc8dd23ae214d84b5dec33fd.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\5026b3550534bca540e24f489284b8e6.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\50534bca540e24f489284b8e6953ad88.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\54ba59c7de13a35276a476420655433a.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\559c7e610b1531871f2fd85a04faeeb2.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\5664c1711b62f15ec83b97bb11e8e0c4.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\5a51625559c7e610b1531871f2fd85a0.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\5b21960c94b0aab4c024a573c692195f.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\5beb48f0be11d0309d1dff09b8405734.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\5c1346e62522325c1b9c4fc9cbe1eca1.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\5e8f14e1e0ae936de314f2d95e6c487f.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\60a633a8d5b2b2b55157b7781e2c706c.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\60b246359c68c836f843dcf41f4dce3c.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\6231002ec4a1fe748f3085f1ce88cbdf.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\6240619ebebe9e9c9d00a4262b4fe4a5.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\625559c7e610b1531871f2fd85a04fae.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\626650908b1cb932a767bf5487ced51b.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\633a8d5b2b2b55157b7781e2c706c75c.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\63b8318ecf467d7ad048df39beb17636.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\6679bff55177a34fc01019eec999fd84.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\66e057db382b8564872a27301a654864.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\677a6b1f2c6d40b3bbba8f6c704801b3.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\67d4dcf9596154efb7cef748d9cbd617.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\68d4b4ef4d95ceea11957998906d3694.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\692195f853af7f8a4df1ec859759b7c8.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\6ad1468996b4a9ce6d840b53a6558038.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\6b83ef461c2a337948a41964c1d4f50a.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\6d3694abb47953b0e4909384b57bb6a0.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\6ddca6ee1af35b65bd9ea42cfcfedb5e.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\6f4d4987ea3b4bae5672a230194c5a08.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\6f67b5df7cdf3f33c3ca4d5060a633a8.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\710d568df17586ad8f3297c819c90895.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\71f2fd85a04faeeb2b535797395305af.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\72d9e593b6be1ac29adbe86f03d900fd.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\7330398846f67b5df7cdf3f33c3ca4d5.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\77e004e8bfb905b78a91391adc0bb223.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\780fd497e1c0e9082ea2c193ac8d551c.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\782707d7c359e27888daefee82519763.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\7936140a2d5fc1443c4e445927738677.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\7ad1cf2eb9d32a3dc907950289e976c7.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\7af2ed9fbb63b28163a745959c039830.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\7b5df7cdf3f33c3ca4d5060a633a8d5b.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\7cb2eb1ef57af2ed9fbb63b28163a745.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\7cdf3f33c3ca4d5060a633a8d5b2b2b5.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\7f0019f7e6af7d7147763bdfb928d788.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\7f32574d6c748c41743c6c08a1d1ad8f.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\7fda8019410b1fcf0625f608b4ce9762.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\80c643782707d7c359e27888daefee82.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\80cae6daedd989517cb8041ed86e5822.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\82ea2c193ac8d551c149b60f2965341c.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\8395e56a6d9ba9d45c3dbc695325ded4.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\85a04faeeb2b535797395305af926a6f.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\87133b51209db6dcdda5cc8a788edaeb.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\88e16d4ca6160127cd1d5ff99c267599.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\8954bb13d3727c7e5e1069646f2f0bb8.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\8b8ec74baddc22268d4b4ef4d95ceea1.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\8cbdf366e057db382b8564872a27301a.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\8eb5a9a8a8d7fcc9df8e5ad89d284483.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\8fa8625605da2023387fd56c04414eaa.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\936de314f2d95e6c487ffa651b477422.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\94a7f32574d6c748c41743c6c08a1d1a.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\9632a3c6f7f7fb2a643f15bd0249ddcc.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\97e1c0e9082ea2c193ac8d551c149b60.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\98da48d679d7c7c8d3d96fb2b87fbbcf.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\998906d3694abb47953b0e4909384b57.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\9c7976c1182df0de51d32128c358d1fd.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\9fc7330398846f67b5df7cdf3f33c3ca.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\a15fc656702fa602bb3c7abacdbd7e6a.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\a3657e4314fe384eb2ba3adfda6c1899.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\a48847ae8395e56a6d9ba9d45c3dbc69.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\a51625559c7e610b1531871f2fd85a04.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\a6a4248a41e8db8b4ed633b456aaafac.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\a6d9ba9d45c3dbc695325ded465efde9.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\a6e51d077bad31c8c5f54ffaa27a6235.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\a9d45c3dbc695325ded465efde988dfb.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\aafac813fe3ccba3e032dd2948a80c64.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\ad43fe2cd066b9fdbc3bbc04a3afe1f1.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\aeeb2b535797395305af926a6f23c5d6.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\af35b65bd9ea42cfcfedb5eb2a0e4b50.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\afe1f119f21b248d152b672ab3492fc6.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\b21960c94b0aab4c024a573c692195f8.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\b70dd094a7f32574d6c748c41743c6c0.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\be4d18d5401f659532897255ce2dd4ae.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\be86f03d900fd197cd955fa095f97845.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\bec33b5e3d68f9d4c331587f9b9d49e2.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\c193ac8d551c149b60f2965341caf528.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\c22268d4b4ef4d95ceea11957998906d.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\c41545ba55aadaa77712a48e11d579d9.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\c4be73749a0d21db70dd094a7f32574d.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\c5a0808bee60b246359c68c836f843dc.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\c656702fa602bb3c7abacdbd7e6afd56.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\c695325ded465efde988dfb96d081533.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\c7e610b1531871f2fd85a04faeeb2b53.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\ca4d5060a633a8d5b2b2b55157b7781e.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\cb1b387133b51209db6dcdda5cc8a788.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\cb2eb1ef57af2ed9fbb63b28163a7459.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\cbb2a365b5574868eb60861ee1ff0b8a.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\cc5cfd263f1f90be28799235026b3550.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\cdf3f33c3ca4d5060a633a8d5b2b2b55.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\cf464aa36bf7c09a3bb0e5ca159410b9.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\cf6644589e532a9ee954f81faedbce39.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\d077bad31c8c5f54ffaa27a623511c38.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\d3694abb47953b0e4909384b57bb6a05.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\d5060a633a8d5b2b2b55157b7781e2c7.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\d6240619ebebe9e9c9d00a4262b4fe4a.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\d694539ef2424a9218697283baa3657e.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\d6bf62f215f0da4ad3a7ab8df9da7386.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\db5eb2a0e4b50889d874c68c030b9afe.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\dc0bb223c4eaf3372eae567c94ea04c6.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\dc70626ab4ec3d46e602b296cc5cfd26.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\dd094a7f32574d6c748c41743c6c08a1.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\dd78294679c9cbb2a365b5574868eb60.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\df366e057db382b8564872a27301a654.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\df8e26031fbb5e52c41545ba55aadaa7.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\e1797c77826f9a7021bab9fc73303988.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\e19769fa2d37d32780fd497e1c0e9082.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\e1e0ae936de314f2d95e6c487ffa651b.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\e2cd066b9fdbc3bbc04a3afe1f119f21.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\e3c84417fda8019410b1fcf0625f608b.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\e4a17af18f72c8e6166a915669c99390.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\e56a6d9ba9d45c3dbc695325ded465ef.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\e5e8f14e1e0ae936de314f2d95e6c487.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\e73749a0d21db70dd094a7f32574d6c7.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\e7998934d417cb2eb1ef57af2ed9fbb6.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\e8bfb905b78a91391adc0bb223c4eaf3.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\e9082ea2c193ac8d551c149b60f29653.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\ea42b4eebc9e5a87e443434ac60af150.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\eb1ef57af2ed9fbb63b28163a745959c.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\eecd70ebce6347c491b37c8c2e5a64a8.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\eff05dec1eb3a70b145a7d8d3b6c0ed7.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\f13dd311a65d2b46d0a6085835c525af.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\f14e1e0ae936de314f2d95e6c487ffa6.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\f62f215f0da4ad3a7ab8df9da7386835.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\f7fdb2d45b21960c94b0aab4c024a573.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\f8e26031fbb5e52c41545ba55aadaa77.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\f8e5ad89d2844837f2a0f1536ad3f6a5.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\faef7fdb2d45b21960c94b0aab4c024a.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\fb905b78a91391adc0bb223c4eaf3372.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\fcd6da15fc656702fa602bb3c7abacdb.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\fdbc3bbc04a3afe1f119f21b248d152b.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\fe1f119f21b248d152b672ab3492fc62.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\ff05dec1eb3a70b145a7d8d3b6c0ed75.jpeg\n",
      "d:/UNet-for-Colonoscopy-Polyp-Segmentation/prediction\\ff55177a34fc01019eec999fd84e679b.jpeg\n"
     ]
    }
   ],
   "source": [
    "def rle_to_string(runs):\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_encode_one_mask(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels[pixels > 225] = 255\n",
    "    pixels[pixels <= 225] = 0\n",
    "    use_padding = False\n",
    "    if pixels[0] or pixels[-1]:\n",
    "        use_padding = True\n",
    "        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n",
    "        pixel_padded[1:-1] = pixels\n",
    "        pixels = pixel_padded\n",
    "    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    if use_padding:\n",
    "        rle = rle - 1\n",
    "    rle[1::2] = rle[1::2] - rle[:-1:2]\n",
    "    \n",
    "    return rle_to_string(rle)\n",
    "\n",
    "def rle2mask(mask_rle, shape=(3,3)):\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "def mask2string(dir):\n",
    "    strings = []\n",
    "    ids = []\n",
    "    ws, hs = [[] for i in range(2)]\n",
    "    for image_id in os.listdir(dir):\n",
    "        id = image_id.split('.')[0]\n",
    "        path = os.path.join(dir, image_id)\n",
    "        print(path)\n",
    "        img = cv2.imread(path)[:,:,::-1]\n",
    "        h, w = img.shape[0], img.shape[1]\n",
    "        for channel in range(2):\n",
    "            ws.append(w)\n",
    "            hs.append(h)\n",
    "            ids.append(f'{id}_{channel}')\n",
    "            string = rle_encode_one_mask(img[:,:,channel])\n",
    "            strings.append(string)\n",
    "    r = {\n",
    "        'ids': ids,\n",
    "        'strings': strings,\n",
    "    }\n",
    "    return r\n",
    "\n",
    "\n",
    "MASK_DIR_PATH = f'{new_cwd}/prediction'\n",
    "dir = MASK_DIR_PATH\n",
    "res = mask2string(dir)\n",
    "df = pd.DataFrame(columns=['Id', 'Expected'])\n",
    "df['Id'] = res['ids']\n",
    "df['Expected'] = res['strings']\n",
    "\n",
    "df.to_csv(f'{new_cwd}submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
